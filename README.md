To run the adversarial attack using the command
```
cd src
python cifar10_train.py
```
This will store two pickle files one with regularization as defined in this [paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Bruce_Hou_Transferable_Adversarial_Perturbations_ECCV_2018_paper.pdf) 
and other without regularization.

You can visualize these perturbations using the visualize_patches.py file.
